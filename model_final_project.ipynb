{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-12-18T16:25:30.080834Z",
          "iopub.status.busy": "2025-12-18T16:25:30.080562Z",
          "iopub.status.idle": "2025-12-18T16:25:41.260024Z",
          "shell.execute_reply": "2025-12-18T16:25:41.259206Z",
          "shell.execute_reply.started": "2025-12-18T16:25:30.080813Z"
        },
        "id": "Muxev71DTUtX",
        "outputId": "867734ed-032c-40e1-a623-055ee0f306e1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import models, transforms\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Settings\n",
        "CONFIG = {\n",
        "    'seed': 42,\n",
        "    'k_folds': 5,\n",
        "    'batch_size': 720,\n",
        "    'num_epochs': 50,\n",
        "    'patience': 5,\n",
        "    'lr_backbone': 4.0e-5,\n",
        "    'lr_head': 3.0e-4,\n",
        "    'weight_decay': 1.5e-4,\n",
        "    'dropout': 0.6,\n",
        "    'img_size': 224,\n",
        "    'num_workers': 2\n",
        "}\n",
        "\n",
        "#Seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    print(f\"Seed set as {seed}.\")\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "# Set seed\n",
        "set_seed(CONFIG['seed'])\n",
        "g = torch.Generator()\n",
        "g.manual_seed(CONFIG['seed'])\n",
        "\n",
        "# Setup Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Avaliable GPU: {torch.cuda.device_count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T16:25:45.160599Z",
          "iopub.status.busy": "2025-12-18T16:25:45.159991Z",
          "iopub.status.idle": "2025-12-18T16:25:45.169727Z",
          "shell.execute_reply": "2025-12-18T16:25:45.169026Z",
          "shell.execute_reply.started": "2025-12-18T16:25:45.160573Z"
        },
        "id": "HaDf8qjYJUy0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Transformations\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(CONFIG['img_size'], scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "#Dataset class\n",
        "class BookCoverDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None, class_to_idx=None):\n",
        "        # Reading CSV\n",
        "        self.df = pd.read_csv(csv_file, sep=';', encoding='ISO-8859-1', header=0, on_bad_lines='warn')\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(self.df['Category'].unique())\n",
        "\n",
        "        if class_to_idx is None:\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        else:\n",
        "            self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = str(self.df.iloc[idx]['Filename'])\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except (OSError, FileNotFoundError):\n",
        "            image = Image.new('RGB', (CONFIG['img_size'], CONFIG['img_size']), (0, 0, 0))\n",
        "\n",
        "        label_str = self.df.iloc[idx]['Category']\n",
        "        label = self.class_to_idx[label_str]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-12-18T16:25:47.288753Z",
          "iopub.status.busy": "2025-12-18T16:25:47.288464Z",
          "iopub.status.idle": "2025-12-18T16:27:34.972172Z",
          "shell.execute_reply": "2025-12-18T16:27:34.971476Z",
          "shell.execute_reply.started": "2025-12-18T16:25:47.288730Z"
        },
        "id": "5w_0fE4pJUy1",
        "outputId": "98eef09f-e1ae-436b-cc33-d221b7aeca3f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#File Search\n",
        "base_search_path = '/kaggle/input'\n",
        "\n",
        "csv_path_train = None\n",
        "csv_path_test = None\n",
        "img_dir = None\n",
        "\n",
        "print(\"Searching folders\")\n",
        "for root, dirs, files in os.walk(base_search_path):\n",
        "    if \"book30-listing-train.csv\" in files:\n",
        "        csv_path_train = os.path.join(root, \"book30-listing-train.csv\")\n",
        "    if \"book30-listing-test.csv\" in files:\n",
        "        csv_path_test = os.path.join(root, \"book30-listing-test.csv\")\n",
        "    if \"224x224\" in dirs:\n",
        "        img_dir = os.path.join(root, \"224x224\")\n",
        "\n",
        "if not (csv_path_train and csv_path_test and img_dir):\n",
        "    raise FileNotFoundError(\"File not found.\")\n",
        "\n",
        "print(f\"Found:\\nTrain CSV: {csv_path_train}\\nTest CSV: {csv_path_test}\\nImg Dir: {img_dir}\")\n",
        "\n",
        "#Creating Dataset\n",
        "#Dataset Train (used for K-Fold)\n",
        "full_train_dataset = BookCoverDataset(\n",
        "    csv_file=csv_path_train,\n",
        "    root_dir=img_dir,\n",
        "    transform=data_transforms['train'] # Transform base\n",
        ")\n",
        "\n",
        "#Dataset Test\n",
        "test_dataset = BookCoverDataset(\n",
        "    csv_file=csv_path_test,\n",
        "    root_dir=img_dir,\n",
        "    transform=data_transforms['val'],\n",
        "    class_to_idx=full_train_dataset.class_to_idx # Same classes as train\n",
        ")\n",
        "\n",
        "#DataLoader Test\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CONFIG['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=CONFIG['num_workers'],\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "print(f\" Dataset Train/Val loaded: {len(full_train_dataset)} images.\")\n",
        "print(f\" Dataset Test loaded: {len(test_dataset)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T16:27:37.823397Z",
          "iopub.status.busy": "2025-12-18T16:27:37.822802Z",
          "iopub.status.idle": "2025-12-18T16:27:37.827601Z",
          "shell.execute_reply": "2025-12-18T16:27:37.826962Z",
          "shell.execute_reply.started": "2025-12-18T16:27:37.823370Z"
        },
        "id": "Q8-9-dnqJUy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model(num_classes):\n",
        "    # Download weights\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # 1. Freezing Backbone\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 2. New head (Classifier)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(CONFIG['dropout']),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T16:27:39.475380Z",
          "iopub.status.busy": "2025-12-18T16:27:39.474788Z",
          "iopub.status.idle": "2025-12-18T16:27:39.483057Z",
          "shell.execute_reply": "2025-12-18T16:27:39.482465Z",
          "shell.execute_reply.started": "2025-12-18T16:27:39.475354Z"
        },
        "id": "9CPDp-EkJUy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Training Function\n",
        "def train_epoch_cycle(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = float('inf')\n",
        "    best_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}', end=' ')\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            samples_processed = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    batch_size = inputs.size(0)\n",
        "                    running_loss += loss.item() * batch_size\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                    samples_processed += batch_size\n",
        "\n",
        "\n",
        "                epoch_loss = running_loss / samples_processed\n",
        "                epoch_acc = running_corrects.double() / samples_processed\n",
        "\n",
        "            if phase == 'val':\n",
        "                print(f'| Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}', end=' ')\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "                if epoch_loss < best_loss:\n",
        "                    best_loss = epoch_loss\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    patience_counter = 0\n",
        "                    print(\"okay!\")\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    print(f\"Increasing Patience Counter: ({patience_counter}/{patience})\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, best_loss, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-18T16:27:41.939144Z",
          "iopub.status.busy": "2025-12-18T16:27:41.938459Z"
        },
        "id": "5zig8mVxJUy2",
        "outputId": "04ad6809-e639-405e-e881-70b4d658457a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Balanced Dataloader\n",
        "#Save Paths\n",
        "BEST_MODEL_PATH = \"best_kfold_model.pth\"\n",
        "fold_results = []\n",
        "fold_losses = []\n",
        "\n",
        "from torch.utils.data import Sampler\n",
        "\n",
        "class BalancedBatchSampler(Sampler):\n",
        "    def __init__(self, dataset, n_classes, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.n_classes = n_classes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        \n",
        "        # Verify split\n",
        "        if self.batch_size % self.n_classes != 0:\n",
        "            raise ValueError(f\"CONFIG ERROR: Batch Size ({self.batch_size}) must be dividible by class number ({self.n_classes}).\")\n",
        "\n",
        "        self.n_samples = self.batch_size // self.n_classes\n",
        "        print(f\"⚖️  Sampler: {self.n_samples} images for each {self.n_classes} class (Batch={self.batch_size})\")\n",
        "\n",
        "        # Extracting all labels of the subset\n",
        "        self.indices = dataset.indices\n",
        "        self.labels = np.array([dataset.dataset.df.iloc[i]['Category'] for i in self.indices])\n",
        "\n",
        "        # Mapping Class-> Index list\n",
        "        self.class_indices = {}\n",
        "        for global_idx, label in zip(self.indices, self.labels):\n",
        "            if label not in self.class_indices:\n",
        "                self.class_indices[label] = []\n",
        "            self.class_indices[label].append(global_idx)\n",
        "\n",
        "        self.classes = list(self.class_indices.keys())\n",
        "\n",
        "        # How many imgs per smallest class\n",
        "        self.min_samples = min([len(indices) for indices in self.class_indices.values()])\n",
        "        # How many complete batches can we do?\n",
        "        self.n_batches = self.min_samples // self.n_samples\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Shuffle indeces per class\n",
        "        for label in self.class_indices:\n",
        "            np.random.shuffle(self.class_indices[label])\n",
        "\n",
        "        # Batch generation\n",
        "        for i in range(self.n_batches):\n",
        "            batch = []\n",
        "            for label in self.classes:\n",
        "                # Take the next n-samples for this class\n",
        "                start = i * self.n_samples\n",
        "                end = (i + 1) * self.n_samples\n",
        "                selected_indices = self.class_indices[label][start:end]\n",
        "                batch.extend(selected_indices)\n",
        "\n",
        "            # Batch shuffling (class not ordered)\n",
        "            np.random.shuffle(batch)\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=CONFIG['k_folds'], shuffle=True, random_state=CONFIG['seed'])\n",
        "\n",
        "# Dataset for Validation\n",
        "val_dataset_ref = copy.deepcopy(full_train_dataset)\n",
        "val_dataset_ref.transform = data_transforms['val']\n",
        "\n",
        "global_best_loss = float('inf')\n",
        "best_fold_idx = -1\n",
        "results = {}\n",
        "\n",
        "print(f\" {CONFIG['k_folds']}-Fold Cross Validation with STRATIFIED BATCH SAMPLING\")\n",
        "print(f\"Best fold will be saved in: {BEST_MODEL_PATH}\")\n",
        "\n",
        "try:\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_train_dataset)):\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"\\n FOLD {fold + 1}/{CONFIG['k_folds']}\")\n",
        "\n",
        "        #Creating Subset\n",
        "        train_sub = Subset(full_train_dataset, train_ids)\n",
        "        val_sub = Subset(val_dataset_ref, val_ids)\n",
        "\n",
        "        #Custom Batch Sampler\n",
        "        custom_batch_sampler = BalancedBatchSampler(\n",
        "            train_sub,\n",
        "            n_classes=len(full_train_dataset.classes),\n",
        "            batch_size= CONFIG['batch_size']\n",
        "        )\n",
        "\n",
        "        #Dataloaders\n",
        "        train_loader = DataLoader(\n",
        "            full_train_dataset,\n",
        "            batch_sampler=custom_batch_sampler,\n",
        "            num_workers=CONFIG['num_workers'],\n",
        "            worker_init_fn=seed_worker\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_sub,\n",
        "            batch_size=CONFIG['batch_size'],\n",
        "            shuffle=False,\n",
        "            num_workers=CONFIG['num_workers'],\n",
        "            worker_init_fn=seed_worker,\n",
        "            generator=g\n",
        "        )\n",
        "\n",
        "        #Model initialization\n",
        "        model = get_model(num_classes=len(full_train_dataset.classes))\n",
        "        model = model.to(device)\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "            real_model = model.module\n",
        "        else:\n",
        "            real_model = model\n",
        "\n",
        "        #Setup Optimizer\n",
        "        for param in real_model.parameters(): param.requires_grad = False\n",
        "        for param in real_model.layer4.parameters(): param.requires_grad = True\n",
        "        for param in real_model.fc.parameters(): param.requires_grad = True\n",
        "\n",
        "        optimizer = optim.Adam([\n",
        "            {'params': real_model.layer4.parameters(), 'lr': CONFIG['lr_backbone']},\n",
        "            {'params': real_model.fc.parameters(), 'lr': CONFIG['lr_head']}\n",
        "        ], weight_decay=CONFIG['weight_decay'])\n",
        "\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        #Fold training\n",
        "        best_model_fold, best_loss_fold, best_acc_fold = train_epoch_cycle(\n",
        "            model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
        "            CONFIG['num_epochs'], CONFIG['patience']\n",
        "        )\n",
        "\n",
        "        #Saving fold\n",
        "        fold_results.append(best_acc_fold.item())\n",
        "        fold_losses.append(best_loss_fold)\n",
        "        fold_path = f\"model_fold_{fold + 1}.pth\"\n",
        "        state_dict = real_model.state_dict()\n",
        "        torch.save(state_dict, fold_path)\n",
        "        print(f\"Fold {fold+1} saved: Loss {best_loss_fold:.4f}, Acc {best_acc_fold:.4f}\")\n",
        "\n",
        "       #Saving best fold\n",
        "        if best_loss_fold < global_best_loss:\n",
        "            print(f\"New best record! ({best_loss_fold:.4f} < {global_best_loss:.4f})\")\n",
        "            global_best_loss = best_loss_fold\n",
        "\n",
        "            print(f\" Overwrite {BEST_MODEL_PATH}...\")\n",
        "            if isinstance(best_model_fold, nn.DataParallel):\n",
        "                torch.save(best_model_fold.module.state_dict(), BEST_MODEL_PATH)\n",
        "            else:\n",
        "                torch.save(best_model_fold.state_dict(), BEST_MODEL_PATH)\n",
        "            best_fold_idx = fold + 1\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted.\")\n",
        "\n",
        "print(\"Summary K-Fold Cross Validation\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if fold_results:\n",
        "    summary_df = pd.DataFrame({\n",
        "        'Fold': range(1, len(fold_results) + 1),\n",
        "        'Loss': fold_losses,\n",
        "        'Accuracy': fold_results\n",
        "    })\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\" Avg. Loss: {np.mean(fold_losses):.4f} (+/- {np.std(fold_losses):.4f})\")\n",
        "    print(f\" Avg. Accuracy: {np.mean(fold_results):.4f} (+/- {np.std(fold_results):.4f})\")\n",
        "else:\n",
        "    print(\"No data available.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "if best_fold_idx != -1:\n",
        "    print(f\" BEST FOLD: {best_fold_idx} with Loss: {global_best_loss:.4f}\")\n",
        "else:\n",
        "    print(\"No model saved!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-12-18T14:21:04.690018Z",
          "iopub.status.idle": "2025-12-18T14:21:04.690260Z",
          "shell.execute_reply": "2025-12-18T14:21:04.690159Z",
          "shell.execute_reply.started": "2025-12-18T14:21:04.690149Z"
        },
        "id": "PJAhVw5hJUy2",
        "outputId": "0f42523a-2959-4c67-b66f-26aa92974c31",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensemble Creation\n",
        "ensemble_models = []\n",
        "num_classes = len(full_train_dataset.classes)\n",
        "\n",
        "print(\"Fold loading\")\n",
        "for i in range(CONFIG['k_folds']):\n",
        "    path = f\"model_fold_{i+1}.pth\"\n",
        "    if os.path.exists(path):\n",
        "        model = get_model(num_classes=num_classes).to(device)\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        ensemble_models.append(model)\n",
        "        print(f\"Fold {i+1} loaded.\")\n",
        "    else:\n",
        "        print(f\"Attention: {path} not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-12-18T14:21:04.691260Z",
          "iopub.status.idle": "2025-12-18T14:21:04.691708Z",
          "shell.execute_reply": "2025-12-18T14:21:04.691558Z",
          "shell.execute_reply.started": "2025-12-18T14:21:04.691543Z"
        },
        "id": "KYFf1GNzJUy2",
        "outputId": "1f653868-9286-4fb5-b76c-04ae38aecc3b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Ensamble Evaluation\n",
        "def evaluate_ensemble(models_list, dataloader):\n",
        "    correct_top1 = 0\n",
        "    correct_top2 = 0\n",
        "    correct_top3 = 0\n",
        "    total = 0\n",
        "\n",
        "    #set eval mode\n",
        "    for m in models_list:\n",
        "        m.eval()\n",
        "\n",
        "    print(f\"Eval of {len(model_list)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Sum ensemble logits\n",
        "            ensemble_logits = None\n",
        "\n",
        "            for model in models_list:\n",
        "                outputs = model(inputs)\n",
        "                #Softmax\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "                if ensemble_logits is None:\n",
        "                    ensemble_logits = probs\n",
        "                else:\n",
        "                    ensemble_logits += prob\n",
        "\n",
        "            avg_probs = ensemble_logits / len(models_list)\n",
        "\n",
        "            #Top-K\n",
        "            _, max_k_preds = torch.topk(avg_probs, k=3, dim=1)\n",
        "            max_k_preds = max_k_preds.t()\n",
        "            target_expanded = labels.view(1, -1).expand_as(max_k_preds)\n",
        "            correct = max_k_preds.eq(target_expanded)\n",
        "\n",
        "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
        "            correct_top2 += correct[:2].reshape(-1).float().sum(0, keepdim=True)\n",
        "            correct_top3 += correct[:3].reshape(-1).float().sum(0, keepdim=True)\n",
        "            total += labels.size(0)\n",
        "\n",
        "    print(f\"\\\\n ENSEMBLE RESULTS ({len(models_list)} Folds):\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\" Top-1 Accuracy: {correct_top1.item()/total*100:.2f}%\")\n",
        "    print(f\" Top-2 Accuracy: {correct_top2.item()/total*100:.2f}%\")\n",
        "    print(f\" Top-3 Accuracy: {correct_top3.item()/total*100:.2f}%\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "evaluate_ensemble(ensemble_models, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "ujCPe771KZ7D",
        "outputId": "60838d1d-d963-4c99-de77-b58af30fe379"
      },
      "outputs": [],
      "source": [
        "# Examples with Top-3 \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "#Denormalize image\n",
        "def denormalize(tensor):\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = tensor.cpu().numpy().transpose((1, 2, 0)) # C,H,W -> H,W,C\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "#Setup\n",
        "#set model in eval mode\n",
        "for m in ensemble_models:\n",
        "    m.eval()\n",
        "\n",
        "class_names = full_train_dataset.classes\n",
        "num_samples = 5\n",
        "indices = random.sample(range(len(test_dataset)), num_samples)\n",
        "\n",
        "#Plot\n",
        "fig, axes = plt.subplots(1, num_samples, figsize=(18, 6))\n",
        "if num_samples == 1: axes = [axes]\n",
        "\n",
        "print(f\"Visualizing {num_samples} examples\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, label = test_dataset[idx]\n",
        "        ax = axes[i]\n",
        "\n",
        "        #Ensemble Inference\n",
        "        input_tensor = image.unsqueeze(0).to(device)\n",
        "        ensemble_probs = None\n",
        "\n",
        "        for model in ensemble_models:\n",
        "            output = model(input_tensor)\n",
        "            probs = F.softmax(output, dim=1)\n",
        "\n",
        "            if ensemble_probs is None:\n",
        "                ensemble_probs = probs\n",
        "            else:\n",
        "                ensemble_probs += probs\n",
        "\n",
        "        # Average of all models probability\n",
        "        avg_probs = ensemble_probs / len(ensemble_models)\n",
        "\n",
        "        # Top-3 ensemble average\n",
        "        top_probs, top_idxs = torch.topk(avg_probs, 3)\n",
        "        top_probs = top_probs.cpu().numpy()[0]\n",
        "        top_idxs = top_idxs.cpu().numpy()[0]\n",
        "\n",
        "        #Visualization\n",
        "        img_show = denormalize(image)\n",
        "        ax.imshow(img_show)\n",
        "        ax.axis('off')\n",
        "\n",
        "        true_name = class_names[label]\n",
        "        pred_name = class_names[top_idxs[0]]\n",
        "        color = 'green' if label == top_idxs[0] else 'red'\n",
        "\n",
        "        ax.set_title(f\"True: {true_name}\\nEnsemble Pred: {pred_name}\", color=color, fontweight='bold', fontsize=9)\n",
        "\n",
        "        # Average prob text\n",
        "        text_str = \"\\n\".join([f\"{class_names[idx]}: {prob*100:.1f}%\" for idx, prob in zip(top_idxs, top_probs)])\n",
        "        ax.text(0.5, -0.15, text_str, transform=ax.transAxes, ha='center', va='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pUyXbi6QMq4X",
        "outputId": "d9c24718-9253-4fe0-9681-56f6a63f0d9c"
      },
      "outputs": [],
      "source": [
        "#Grad-CAM Ensemble (Avg Heatmap)\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def compute_ensemble_gradcam(models_list, img_tensor):\n",
        "    \"\"\"GradCam of Ensemble of {len(ensemble_models)} models.\"\"\"\n",
        "    combined_heatmap = None\n",
        "\n",
        "    for model in models_list:\n",
        "        model.eval()\n",
        "        activations = {}\n",
        "        gradients = {}\n",
        "\n",
        "        def get_activations(name):\n",
        "            return lambda m, i, o: activations.update({name: o.detach()})\n",
        "        def get_gradients(name):\n",
        "            return lambda m, gi, go: gradients.update({name: go[0].detach()})\n",
        "\n",
        "        # Use last layer of model\n",
        "        target_layer = model.layer4[-1]\n",
        "        h_fwd = target_layer.register_forward_hook(get_activations('feat'))\n",
        "        h_bwd = target_layer.register_full_backward_hook(get_gradients('feat'))\n",
        "\n",
        "        try:\n",
        "            input_t = img_tensor.unsqueeze(0).to(device)\n",
        "            input_t.requires_grad = True\n",
        "            output = model(input_t)\n",
        "            pred_idx = output.argmax(dim=1).item()\n",
        "\n",
        "            model.zero_grad()\n",
        "            output[0, pred_idx].backward()\n",
        "\n",
        "            acts = activations['feat'][0]\n",
        "            grads = gradients['feat'][0]\n",
        "            weights = torch.mean(grads, dim=(1, 2))\n",
        "\n",
        "            cam = torch.zeros(acts.shape[1:], dtype=torch.float32).to(device)\n",
        "            for i, w in enumerate(weights):\n",
        "                cam += w * acts[i]\n",
        "\n",
        "            cam = F.relu(cam)\n",
        "            cam = F.interpolate(cam.unsqueeze(0).unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().cpu().detach().numpy()\n",
        "\n",
        "            \n",
        "            cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam) + 1e-8)\n",
        "\n",
        "            if combined_heatmap is None:\n",
        "                combined_heatmap = cam\n",
        "            else:\n",
        "                combined_heatmap += cam\n",
        "        finally:\n",
        "            h_fwd.remove()\n",
        "            h_bwd.remove()\n",
        "\n",
        "    return combined_heatmap / len(models_list)\n",
        "\n",
        "#Plot\n",
        "print(f\"Average GradCam of Ensemble of {len(ensemble_models)} models\")\n",
        "idxs = random.sample(range(len(test_dataset)), 3)\n",
        "\n",
        "for idx in idxs:\n",
        "    img, label = test_dataset[idx]\n",
        "    avg_heatmap = compute_ensemble_gradcam(ensemble_models, img)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        ens_logits = None\n",
        "        for m in ensemble_models:\n",
        "            out = m(img.unsqueeze(0).to(device))\n",
        "            p = F.softmax(out, dim=1)\n",
        "            ens_logits = p if ens_logits is None else ens_logits + p\n",
        "        pred = (ens_logits / len(ensemble_models)).argmax(dim=1).item()\n",
        "\n",
        "    img_show = denormalize(img)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_show)\n",
        "    plt.title(f\"Original\\nTrue: {class_names[label]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_show)\n",
        "    plt.imshow(avg_heatmap, cmap='jet', alpha=0.5)\n",
        "    plt.title(f\"Ensemble Grad-CAM\\nPred: {class_names[pred]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "_O25Rws0M-x4",
        "outputId": "b5ac792a-17aa-49bd-8c45-8bab2abcc9e2"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix Ensemble\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(f\"Confusion matrix Ensemble of {len(ensemble_models)} models\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for m in ensemble_models:\n",
        "    m.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Ensemble\n",
        "        ensemble_probs = None\n",
        "\n",
        "        for model in ensemble_models:\n",
        "            outputs = model(inputs)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "            if ensemble_probs is None:\n",
        "                ensemble_probs = probs\n",
        "            else:\n",
        "                ensemble_probs += probs\n",
        "\n",
        "        # Average probabilities\n",
        "        avg_probs = ensemble_probs / len(ensemble_models)\n",
        "        _, preds = torch.max(avg_probs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "# Matrix Generation\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted (Ensemble)', fontsize=12)\n",
        "plt.ylabel('Real', fontsize=12)\n",
        "plt.title(f'Confusion Matrix - Ensemble of {len(ensemble_models)} Models', fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4800241,
          "sourceId": 8124024,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
