{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muxev71DTUtX",
        "outputId": "65622fca-a5a4-45ed-fcab-aaa5d1e2f4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Trovato /content/drive/MyDrive/dataset.zip. Inizio estrazione...\n",
            "‚úÖ Estrazione completata!\n"
          ]
        }
      ],
      "source": [
        "########CELLA 1###############\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 1. Monta Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Configurazione Percorsi\n",
        "# Assumiamo che il file sia nella root del tuo Drive.\n",
        "# Se √® in una sottocartella, modifica in: '/content/drive/MyDrive/NOME_CARTELLA/dataset.zip'\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "extract_to = '/content/dataset_unzipped'\n",
        "\n",
        "# 3. Estrazione\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"Trovato {zip_path}. Inizio estrazione...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"‚úÖ Estrazione completata!\")\n",
        "else:\n",
        "    print(f\"‚ùå ERRORE: Non trovo il file '{zip_path}'.\")\n",
        "    print(\"Controlla di averlo caricato su Drive e che il nome sia esattamente 'dataset.zip' (tutto minuscolo).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFPreKw1Tb8v"
      },
      "outputs": [],
      "source": [
        "############CELLA 2#################\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class BookCoverDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None, class_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Percorso al file CSV.\n",
        "            root_dir (string): Directory che contiene le immagini (224x224).\n",
        "            transform (callable, optional): Trasformazioni (Tensor, Normalize).\n",
        "        \"\"\"\n",
        "        # Lettura CSV con i parametri corretti scoperti prima (sep=; encoding=ISO...)\n",
        "        self.df = pd.read_csv(csv_file, sep=';', encoding='ISO-8859-1', header=0, on_bad_lines='warn')\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Ordina le classi per garantire coerenza\n",
        "        self.classes = sorted(self.df['Category'].unique())\n",
        "\n",
        "        # Mappa Stringa -> Intero\n",
        "        if class_to_idx is None:\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        else:\n",
        "            self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Recupera nome file e costruisce percorso\n",
        "        img_name = str(self.df.iloc[idx]['Filename'])\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        # Caricamento Immagine\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except (OSError, FileNotFoundError):\n",
        "            # Gestione immagine mancante (crea immagine nera)\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        # Label\n",
        "        label_str = self.df.iloc[idx]['Category']\n",
        "        label = self.class_to_idx[label_str]\n",
        "\n",
        "        # Trasformazioni\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- CONFIGURAZIONE TRASFORMAZIONI ---\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)), # Nel validation NON facciamo augmentation\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKMs6qpuTiSO",
        "outputId": "a76b48b6-d6b6-4fb3-a35a-66fe6fbf660f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Scansione cartelle in corso...\n",
            "   -> CSV Trovato: /content/dataset_unzipped/dataset/book30-listing-train.csv\n",
            "   -> Cartella Immagini Trovata: /content/dataset_unzipped/dataset/title30cat/224x224\n",
            "\n",
            "‚úÖ File trovati! Creazione Dataset in corso...\n",
            "Dataset caricato correttamente con 51300 libri.\n",
            "Numero di classi (Generi): 30\n",
            "\n",
            "üñ•Ô∏è Device attivo: cuda\n",
            "üöÄ Perfetto! La GPU NVIDIA T4 √® pronta a spingere.\n",
            "\n",
            "Test Shape Tensore: torch.Size([3, 224, 224]) (Deve essere 3, 224, 224)\n"
          ]
        }
      ],
      "source": [
        "#################CELLA 3####################\n",
        "# Cerchiamo i percorsi corretti navigando tra le cartelle estratte\n",
        "base_search_path = '/content/dataset_unzipped'\n",
        "csv_path = None\n",
        "img_dir = None\n",
        "\n",
        "print(\"üîç Scansione cartelle in corso...\")\n",
        "\n",
        "for root, dirs, files in os.walk(base_search_path):\n",
        "    # Cerchiamo il CSV di training\n",
        "    if \"book30-listing-train.csv\" in files:\n",
        "        csv_path = os.path.join(root, \"book30-listing-train.csv\")\n",
        "        print(f\"   -> CSV Trovato: {csv_path}\")\n",
        "\n",
        "    # Cerchiamo la cartella specifica delle immagini\n",
        "    if \"224x224\" in dirs:\n",
        "        img_dir = os.path.join(root, \"224x224\")\n",
        "        print(f\"   -> Cartella Immagini Trovata: {img_dir}\")\n",
        "\n",
        "# --- VERIFICA E CREAZIONE DATASET ---\n",
        "if csv_path and img_dir:\n",
        "    print(\"\\n‚úÖ File trovati! Creazione Dataset in corso...\")\n",
        "\n",
        "    # Creiamo il dataset\n",
        "    train_dataset = BookCoverDataset(\n",
        "        csv_file=csv_path,\n",
        "        root_dir=img_dir,\n",
        "        transform=data_transforms['train']\n",
        "    )\n",
        "\n",
        "    # TEST RAPIDO\n",
        "    print(f\"Dataset caricato correttamente con {len(train_dataset)} libri.\")\n",
        "    print(f\"Numero di classi (Generi): {len(train_dataset.classes)}\")\n",
        "\n",
        "    # Verifica GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"\\nüñ•Ô∏è Device attivo: {device}\")\n",
        "    if device.type == 'cuda':\n",
        "        print(\"üöÄ Perfetto! La GPU NVIDIA T4 √® pronta a spingere.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è ATTENZIONE: Stai usando la CPU. Vai su Modifica -> Impostazioni Notebook -> Hardware Accelerator -> T4 GPU\")\n",
        "\n",
        "    # Test estrazione di un elemento\n",
        "    img, label = train_dataset[0]\n",
        "    print(f\"\\nTest Shape Tensore: {img.shape} (Deve essere 3, 224, 224)\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå ERRORE CRITICO: Non ho trovato i file necessari.\")\n",
        "    print(\"Controlla il contenuto dello zip. Cerco 'book30-listing-train.csv' e una cartella '224x224'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmRJEa8Zb3sI",
        "outputId": "4e258115-e358-4324-d5c9-2c46891485b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Split completato:\n",
            "   -> Training Set: 41040 immagini\n",
            "   -> Validation Set: 10260 immagini\n",
            "‚úÖ Dataloaders pronti (Batch size: 64)\n"
          ]
        }
      ],
      "source": [
        "###############CELLA 4##############\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 1. Divisione Train / Validation (80% / 20%)\n",
        "total_size = len(train_dataset)\n",
        "train_len = int(0.8 * total_size)\n",
        "val_len = total_size - train_len\n",
        "\n",
        "# random_split mischia gli indici e crea due sotto-dataset\n",
        "train_subset, val_subset = random_split(train_dataset, [train_len, val_len])\n",
        "\n",
        "print(f\"üìä Split completato:\")\n",
        "print(f\"   -> Training Set: {len(train_subset)} immagini\")\n",
        "print(f\"   -> Validation Set: {len(val_subset)} immagini\")\n",
        "\n",
        "# 2. Creazione dei DataLoader (I 'nastri trasportatori' per la GPU)\n",
        "# Batch Size 64 √® ottimale per la GPU T4 di Colab (usa bene la memoria senza esaurirla)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"‚úÖ Dataloaders pronti (Batch size: {BATCH_SIZE})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjMKEnk_ldxd",
        "outputId": "1a9b0b96-6dd8-400c-d3f6-7e6938f4b309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaricamento pesi ResNet50 (ImageNet)...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 229MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Modello ResNet50 caricato e modificato per 30 classi.\n",
            "   -> Backbone (corpo): Congelato ‚ùÑÔ∏è\n",
            "   -> Head (testa): Pronta per l'addestramento üî•\n"
          ]
        }
      ],
      "source": [
        "###############CELLA 5###################\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_model(num_classes=30):\n",
        "    print(\"Scaricamento pesi ResNet50 (ImageNet)...\")\n",
        "    # Scarichiamo la versione pi√π aggiornata dei pesi\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # 1. FREEZING: Congeliamo tutti i parametri\n",
        "    # Questo impedisce che durante il training modifichiamo i filtri che sanno gi√† \"vedere\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 2. Sostituzione dell'ultimo layer (Fully Connected)\n",
        "    # ResNet50 ha 2048 feature in ingresso all'ultimo layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "\n",
        "    # Creiamo il nuovo layer classificatore.\n",
        "    # Nota: Di default, i nuovi layer hanno requires_grad=True, quindi QUESTI verranno addestrati.\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512), # Strato intermedio per imparare combinazioni complesse\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),          # Dropout per evitare overfitting (tecnica standard)\n",
        "        nn.Linear(512, num_classes) # Output finale: 30 probabilit√†\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Istanziamo il modello e lo spostiamo sulla GPU\n",
        "model = get_model(num_classes=len(train_dataset.classes))\n",
        "model = model.to(device) # Sposta tutto sulla GPU T4\n",
        "\n",
        "print(\"\\nü§ñ Modello ResNet50 caricato e modificato per 30 classi.\")\n",
        "print(\"   -> Backbone (corpo): Congelato ‚ùÑÔ∏è\")\n",
        "print(\"   -> Head (testa): Pronta per l'addestramento üî•\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVFl2zD0kibA",
        "outputId": "ab257a74-cb0a-499c-e5d8-38680b6b441c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Il modello migliore verr√† salvato in: /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth\n",
            "\n",
            "üîí Congelamento preventivo di tutta la rete...\n",
            "üîì Scongelamento della Testa (FC) e dell'Ultimo Blocco (Layer4)...\n",
            "üî• Parametri pronti per l'addestramento: 16,029,214\n",
            "üöÄ Avvio Training con Salvataggio su Drive...\n",
            "\n",
            "Epoch 1/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 3.0169 Acc: 0.1749\n",
            "val Loss: 2.7909 Acc: 0.2244\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 2/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.7463 Acc: 0.2366\n",
            "val Loss: 2.6784 Acc: 0.2509\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 3/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.6426 Acc: 0.2582\n",
            "val Loss: 2.6170 Acc: 0.2646\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 4/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.5655 Acc: 0.2806\n",
            "val Loss: 2.5879 Acc: 0.2731\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 5/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.5113 Acc: 0.2901\n",
            "val Loss: 2.5530 Acc: 0.2815\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 6/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.4553 Acc: 0.3045\n",
            "val Loss: 2.5473 Acc: 0.2835\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 7/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.4075 Acc: 0.3169\n",
            "val Loss: 2.5231 Acc: 0.2934\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 8/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.3609 Acc: 0.3282\n",
            "val Loss: 2.5203 Acc: 0.2921\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 9/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.3155 Acc: 0.3403\n",
            "val Loss: 2.5085 Acc: 0.2985\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 10/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.2752 Acc: 0.3494\n",
            "val Loss: 2.5167 Acc: 0.2942\n",
            "‚ö†Ô∏è Nessun miglioramento. Patience: 1/6\n",
            "\n",
            "Epoch 11/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.2308 Acc: 0.3615\n",
            "val Loss: 2.5118 Acc: 0.2907\n",
            "‚ö†Ô∏è Nessun miglioramento. Patience: 2/6\n",
            "\n",
            "Epoch 12/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.1930 Acc: 0.3689\n",
            "val Loss: 2.5048 Acc: 0.3001\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 13/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.1473 Acc: 0.3843\n",
            "val Loss: 2.5105 Acc: 0.3018\n",
            "‚ö†Ô∏è Nessun miglioramento. Patience: 1/6\n",
            "\n",
            "Epoch 14/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.1149 Acc: 0.3888\n",
            "val Loss: 2.5039 Acc: 0.3015\n",
            "‚úÖ Miglioramento! Salvataggio modello in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 15/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.0706 Acc: 0.4016\n",
            "val Loss: 2.5167 Acc: 0.3024\n",
            "‚ö†Ô∏è Nessun miglioramento. Patience: 1/6\n",
            "\n",
            "Epoch 16/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 2.0284 Acc: 0.4131\n",
            "val Loss: 2.5270 Acc: 0.3029\n",
            "‚ö†Ô∏è Nessun miglioramento. Patience: 2/6\n",
            "\n",
            "Epoch 17/30\n",
            "----------\n",
            "üìâ LR attuale -> Backbone: 1.0e-05 | Head: 1.0e-04\n",
            "train Loss: 1.9858 Acc: 0.4238\n"
          ]
        }
      ],
      "source": [
        "################## CELLA 6 (TRAINING + SALVATAGGIO SU DRIVE) #################\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from torchvision import models\n",
        "import os\n",
        "\n",
        "# --- 0. CONFIGURAZIONE SALVATAGGIO ---\n",
        "# Definiamo dove salvare il modello su Google Drive\n",
        "# Assicurati che questa cartella esista o il codice la creer√†\n",
        "SAVE_PATH = '/content/drive/MyDrive/Modelli_BookCover'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "MODEL_NAME = 'best_resnet50_finetuned.pth'\n",
        "FULL_MODEL_PATH = os.path.join(SAVE_PATH, MODEL_NAME)\n",
        "\n",
        "print(f\"üíæ Il modello migliore verr√† salvato in: {FULL_MODEL_PATH}\")\n",
        "\n",
        "# Scongelamento Selettivo\n",
        "print(\"\\nüîí Congelamento preventivo di tutta la rete...\")\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"üîì Scongelamento della Testa (FC) e dell'Ultimo Blocco (Layer4)...\")\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Parametri da aggiornare\n",
        "params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
        "print(f\"üî• Parametri pronti per l'addestramento: {sum(p.numel() for p in params_to_update):,}\")\n",
        "\n",
        "# Loss e Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer con LR differenziato\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.layer4.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.fc.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "# Parametri Epoche\n",
        "NUM_EPOCHS = 30\n",
        "ES_PATIENCE = 6\n",
        "\n",
        "# --- 3. FUNZIONE DI TRAINING CON SALVATAGGIO ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, es_patience=6):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Inizializziamo con i pesi attuali\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        lr_backbone = optimizer.param_groups[0]['lr']\n",
        "        lr_head = optimizer.param_groups[1]['lr']\n",
        "        print(f\"üìâ LR attuale -> Backbone: {lr_backbone:.1e} | Head: {lr_head:.1e}\")\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total_samples = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                total_samples += inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / total_samples\n",
        "            epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "            if phase == 'train':\n",
        "                history['train_loss'].append(epoch_loss)\n",
        "                history['train_acc'].append(epoch_acc.item())\n",
        "            else:\n",
        "                history['val_loss'].append(epoch_loss)\n",
        "                history['val_acc'].append(epoch_acc.item())\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # --- LOGICA SALVATAGGIO MIGLIOR MODELLO ---\n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_val_loss:\n",
        "                    best_val_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    patience_counter = 0\n",
        "\n",
        "                    # SALVATAGGIO SU DISCO (DRIVE)\n",
        "                    print(f\"‚úÖ Miglioramento! Salvataggio modello in {FULL_MODEL_PATH}...\")\n",
        "                    torch.save(model.state_dict(), FULL_MODEL_PATH)\n",
        "\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    print(f\"‚ö†Ô∏è Nessun miglioramento. Patience: {patience_counter}/{es_patience}\")\n",
        "\n",
        "        if patience_counter >= es_patience:\n",
        "            print(f\"\\n‚èπÔ∏è Early Stopping attivato! Stop training.\")\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f'\\nAddestramento completato in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Miglior Val Loss: {best_val_loss:.4f}')\n",
        "\n",
        "    # Ricarichiamo i pesi migliori (sia in memoria che da file per sicurezza)\n",
        "    print(\"üîÑ Caricamento dei pesi migliori per la valutazione finale...\")\n",
        "    model.load_state_dict(torch.load(FULL_MODEL_PATH))\n",
        "    return model\n",
        "\n",
        "# --- AVVIO ---\n",
        "print(\"üöÄ Avvio Training con Salvataggio su Drive...\")\n",
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS, es_patience=ES_PATIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMJNadJZkeyb"
      },
      "outputs": [],
      "source": [
        "################## CELLA DI CARICAMENTO (NO TRAINING) #################\n",
        "#######NEL CASO IN CUI TU VOGLIA CARICARE UN MODELLO SALVATO IN PRECEDENZA NEL DRIVE\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# 1. Definizione Percorso (Lo stesso usato per il salvataggio)\n",
        "SAVE_PATH = '/content/drive/MyDrive/Modelli_BookCover'\n",
        "MODEL_NAME = 'best_resnet50_finetuned.pth'\n",
        "FULL_MODEL_PATH = os.path.join(SAVE_PATH, MODEL_NAME)\n",
        "\n",
        "# 2. Verifica esistenza file\n",
        "if os.path.exists(FULL_MODEL_PATH):\n",
        "    print(f\"üìÇ Trovato modello salvato: {FULL_MODEL_PATH}\")\n",
        "\n",
        "    # 3. Caricamento dei pesi nello scheletro creato nella Cella 5\n",
        "    # map_location assicura che funzioni sia su CPU che GPU\n",
        "    state_dict = torch.load(FULL_MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    # Spostiamo il modello sulla GPU (se disponibile)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Mettiamo il modello in modalit√† valutazione (blocca dropout, batchnorm, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"‚úÖ Pesi caricati con successo! Il modello √® pronto per la valutazione.\")\n",
        "    print(\"‚è≠Ô∏è Ora puoi eseguire direttamente le celle 7 e 8.\")\n",
        "else:\n",
        "    print(f\"‚ùå ERRORE: Non trovo il file in {FULL_MODEL_PATH}\")\n",
        "    print(\"Assicurati di aver fatto almeno un training completo in precedenza.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Mou0UYgdKN"
      },
      "outputs": [],
      "source": [
        "##################CELLA 7#################\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(model, dataloader, classes):\n",
        "    model.eval() # Modalit√† valutazione\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    print(\"üìä Calcolo delle predizioni sul Validation Set...\")\n",
        "    with torch.no_grad(): # Disabilita il calcolo dei gradienti (risparmia memoria)\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Spostiamo su CPU e convertiamo in numpy\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calcolo della matrice\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Normalizzazione (opzionale, per vedere le % invece dei numeri assoluti)\n",
        "    # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(20, 16)) # Dimensioni grandi per farci stare 30 classi\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "\n",
        "    plt.ylabel('Vero Genere (True Label)', fontsize=14)\n",
        "    plt.xlabel('Genere Predetto (Predicted Label)', fontsize=14)\n",
        "    plt.title('Matrice di Confusione - Generi Letterari', fontsize=18)\n",
        "    plt.xticks(rotation=90) # Ruota le etichette per leggerle meglio\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "# Eseguiamo la funzione usando il modello addestrato\n",
        "# Assicurati che 'trained_model' sia disponibile (dopo la Cella 6)\n",
        "print(\"Generazione grafico in corso...\")\n",
        "plot_confusion_matrix(model, val_loader, train_dataset.classes) #cambiato (vedi se \"model\" funziona comunque anche se traini il modello da capo, altrimenti rimetti \"trained_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsj7PXwZ2Af-"
      },
      "outputs": [],
      "source": [
        "################## CELLA 8#################\n",
        "#METRICHE PAPER (TOP-1, TOP-2, TOP-3)\n",
        "def evaluate_paper_metrics(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    correct_top1 = 0\n",
        "    correct_top2 = 0\n",
        "    correct_top3 = 0\n",
        "    total = 0\n",
        "\n",
        "    print(\"üìè Calcolo metriche Top-k (Come nel Paper)...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 1. Calcoliamo l'output del modello\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 2. Prendiamo le prime 3 predizioni pi√π alte (Top-3)\n",
        "            # k=3 perch√© ci servono Top-1, Top-2 e Top-3\n",
        "            _, max_k_preds = torch.topk(outputs, k=3, dim=1)\n",
        "\n",
        "            # 3. Trasponiamo la matrice per facilitare il confronto\n",
        "            # Ora max_k_preds ha shape [3, batch_size]\n",
        "            max_k_preds = max_k_preds.t()\n",
        "\n",
        "            # 4. Creiamo una matrice di etichette ripetute per confrontarle\n",
        "            target_expanded = labels.view(1, -1).expand_as(max_k_preds)\n",
        "\n",
        "            # 5. Confronto: Otteniamo una matrice di True/False\n",
        "            # Se la cella (k, i) √® True, vuol dire che la k-esima predizione per l'immagine i √® corretta\n",
        "            correct = max_k_preds.eq(target_expanded)\n",
        "\n",
        "            # --- AGGIORNAMENTO CONTATORI ---\n",
        "\n",
        "            # Top-1: Controlliamo solo la prima riga (la predizione #1)\n",
        "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            # Top-2: Controlliamo le prime due righe (predizione #1 O predizione #2)\n",
        "            correct_top2 += correct[:2].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            # Top-3: Controlliamo le prime tre righe\n",
        "            correct_top3 += correct[:3].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # Calcolo percentuali finali\n",
        "    acc_top1 = correct_top1.item() / total * 100\n",
        "    acc_top2 = correct_top2.item() / total * 100\n",
        "    acc_top3 = correct_top3.item() / total * 100\n",
        "\n",
        "    print(f\"\\nüìä RISULTATI DEL PAPER (su {total} immagini di test):\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"üîπ Top-1 Accuracy: {acc_top1:.2f}%  (Paper AlexNet: 24.7%)\")\n",
        "    print(f\"üîπ Top-2 Accuracy: {acc_top2:.2f}%  (Paper AlexNet: 33.1%)\")\n",
        "    print(f\"üîπ Top-3 Accuracy: {acc_top3:.2f}%  (Paper AlexNet: 40.3%)\")\n",
        "    print(\"-\" * 40)\n",
        "    return acc_top1, acc_top2, acc_top3\n",
        "\n",
        "# Esegui la valutazione\n",
        "evaluate_paper_metrics(model, val_loader) #cambiato (vedi se \"model\" funziona comunque anche se traini il modello da capo, altrimenti rimetti \"trained_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
