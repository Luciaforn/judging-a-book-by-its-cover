{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muxev71DTUtX",
        "outputId": "78492944-6dbc-46c8-a40c-c33ea359dd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Trovato /content/drive/MyDrive/dataset.zip. Inizio estrazione...\n",
            "‚úÖ Estrazione completata!\n"
          ]
        }
      ],
      "source": [
        "########CELLA 1###############\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# 1. Monta Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Configurazione Percorsi\n",
        "# Assumiamo che il file sia nella root del tuo Drive.\n",
        "# Se √® in una sottocartella, modifica in: '/content/drive/MyDrive/NOME_CARTELLA/dataset.zip'\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "extract_to = '/content/dataset_unzipped'\n",
        "\n",
        "# 3. Estrazione\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"Trovato {zip_path}. Inizio estrazione...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"‚úÖ Estrazione completata!\")\n",
        "else:\n",
        "    print(f\"‚ùå ERRORE: Non trovo il file '{zip_path}'.\")\n",
        "    print(\"Controlla di averlo caricato su Drive e che il nome sia esattamente 'dataset.zip' (tutto minuscolo).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fPAy_OC-Rsr",
        "outputId": "83abb8a3-23a3-4cf7-d5eb-52e3fd6ebfcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üå± Seme impostato su 42. Riproducibilit√† attivata.\n"
          ]
        }
      ],
      "source": [
        "##########CELLA 1.5 (RIPRODUCIBILITA')###########\n",
        "################# AGGIUNTA PER RIPRODUCIBILIT√Ä (SEEDING) #################\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # Se usi multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"üå± Seme impostato su {seed}. Riproducibilit√† attivata.\")\n",
        "\n",
        "# Impostiamo il seed a 42 (o il numero fortunato che preferisci)\n",
        "SEED_VALUE = 42\n",
        "set_all_seeds(SEED_VALUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YFPreKw1Tb8v"
      },
      "outputs": [],
      "source": [
        "############CELLA 2#################\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class BookCoverDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None, class_to_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Percorso al file CSV.\n",
        "            root_dir (string): Directory che contiene le immagini (224x224).\n",
        "            transform (callable, optional): Trasformazioni (Tensor, Normalize).\n",
        "        \"\"\"\n",
        "        # Lettura CSV con i parametri corretti scoperti prima (sep=; encoding=ISO...)\n",
        "        self.df = pd.read_csv(csv_file, sep=';', encoding='ISO-8859-1', header=0, on_bad_lines='warn')\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Ordina le classi per garantire coerenza\n",
        "        self.classes = sorted(self.df['Category'].unique())\n",
        "\n",
        "        # Mappa Stringa -> Intero\n",
        "        if class_to_idx is None:\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "        else:\n",
        "            self.class_to_idx = class_to_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Recupera nome file e costruisce percorso\n",
        "        img_name = str(self.df.iloc[idx]['Filename'])\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "\n",
        "        # Caricamento Immagine\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except (OSError, FileNotFoundError):\n",
        "            # Gestione immagine mancante (crea immagine nera)\n",
        "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "\n",
        "        # Label\n",
        "        label_str = self.df.iloc[idx]['Category']\n",
        "        label = self.class_to_idx[label_str]\n",
        "\n",
        "        # Trasformazioni\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- CONFIGURAZIONE TRASFORMAZIONI ---\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)), # Nel validation NON facciamo augmentation\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKMs6qpuTiSO",
        "outputId": "7ff23f3b-2187-4d70-f806-d1c4bca9d2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Scansione cartelle in corso...\n",
            "   -> CSV Training Trovato: /content/dataset_unzipped/dataset/book30-listing-train.csv\n",
            "   -> CSV Test Trovato: /content/dataset_unzipped/dataset/book30-listing-test.csv\n",
            "   -> Cartella Immagini Trovata: /content/dataset_unzipped/dataset/title30cat/224x224\n",
            "\n",
            "‚úÖ File trovati! Creazione Dataset in corso...\n",
            "Dataset di Training/Validation caricato correttamente con 51300 libri.\n",
            "Dataset di Test caricato correttamente con 5700 libri.\n",
            "Numero di classi (Generi): 30\n",
            "\n",
            "üñ•Ô∏è Device attivo: cpu\n",
            "‚ö†Ô∏è ATTENZIONE: Stai usando la CPU.\n",
            "\n",
            "Test Shape Tensore: torch.Size([3, 224, 224]) (Deve essere 3, 224, 224)\n"
          ]
        }
      ],
      "source": [
        "#################CELLA 3 (MODIFICATA PER IL TEST SET)####################\n",
        "# Cerchiamo i percorsi corretti navigando tra le cartelle estratte\n",
        "base_search_path = '/content/dataset_unzipped'\n",
        "csv_path_train = None\n",
        "csv_path_test = None\n",
        "img_dir = None\n",
        "\n",
        "print(\"üîç Scansione cartelle in corso...\")\n",
        "\n",
        "for root, dirs, files in os.walk(base_search_path):\n",
        "    # Cerchiamo il CSV di training\n",
        "    if \"book30-listing-train.csv\" in files:\n",
        "        csv_path_train = os.path.join(root, \"book30-listing-train.csv\")\n",
        "        print(f\"   -> CSV Training Trovato: {csv_path_train}\")\n",
        "\n",
        "    # Cerchiamo il CSV di test\n",
        "    if \"book30-listing-test.csv\" in files:\n",
        "        csv_path_test = os.path.join(root, \"book30-listing-test.csv\")\n",
        "        print(f\"   -> CSV Test Trovato: {csv_path_test}\")\n",
        "\n",
        "    # Cerchiamo la cartella specifica delle immagini\n",
        "    if \"224x224\" in dirs:\n",
        "        img_dir = os.path.join(root, \"224x224\")\n",
        "        print(f\"   -> Cartella Immagini Trovata: {img_dir}\")\n",
        "\n",
        "# --- VERIFICA E CREAZIONE DATASET ---\\n\n",
        "if csv_path_train and csv_path_test and img_dir:\n",
        "    print(\"\\n‚úÖ File trovati! Creazione Dataset in corso...\")\n",
        "\n",
        "    # 1. Creazione del Dataset di Training/Validation\n",
        "    # Usiamo il transform di 'train' per tutte le immagini che saranno divise\n",
        "    train_val_dataset = BookCoverDataset(\n",
        "        csv_file=csv_path_train,\n",
        "        root_dir=img_dir,\n",
        "        transform=data_transforms['train'] # Nota: useremo 'val' transform dopo lo split\n",
        "    )\n",
        "\n",
        "    # 2. Creazione del Dataset di Test (deve avere le stesse classi)\n",
        "    # Importante: usiamo il class_to_idx del training per mantenere la mappatura (es. 0 = Action/Adventure)\n",
        "    test_dataset = BookCoverDataset(\n",
        "        csv_file=csv_path_test,\n",
        "        root_dir=img_dir,\n",
        "        transform=data_transforms['val'], # Per il test usiamo le trasformazioni del validation (solo resize/normalize)\n",
        "        class_to_idx=train_val_dataset.class_to_idx\n",
        "    )\n",
        "\n",
        "    # TEST RAPIDO\n",
        "    print(f\"Dataset di Training/Validation caricato correttamente con {len(train_val_dataset)} libri.\")\n",
        "    print(f\"Dataset di Test caricato correttamente con {len(test_dataset)} libri.\")\n",
        "    print(f\"Numero di classi (Generi): {len(train_val_dataset.classes)}\")\n",
        "\n",
        "    # Verifica GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"\\nüñ•Ô∏è Device attivo: {device}\")\n",
        "    if device.type == 'cuda':\n",
        "        print(\"üöÄ Perfetto! La GPU NVIDIA T4 √® pronta a spingere.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è ATTENZIONE: Stai usando la CPU.\")\n",
        "\n",
        "    # Test estrazione di un elemento\n",
        "    img, label = train_val_dataset[0]\n",
        "    print(f\"\\nTest Shape Tensore: {img.shape} (Deve essere 3, 224, 224)\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå ERRORE CRITICO: Non ho trovato i file necessari.\")\n",
        "    print(\"Controlla il contenuto dello zip. Cerco 'book30-listing-train.csv', 'book30-listing-test.csv' e una cartella '224x224'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmRJEa8Zb3sI",
        "outputId": "82868770-160b-4bba-d1cb-5652641ba6f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Split completato (dal set di Training/Validation):\n",
            "   -> Training Set: 41040 immagini\n",
            "   -> Validation Set: 10260 immagini\n",
            "   -> Test Set (dal file test.csv): 5700 immagini\n",
            "‚úÖ Dataloaders pronti (Batch size: 64)\n"
          ]
        }
      ],
      "source": [
        "###############CELLA 4 (MODIFICATA PER IL TEST SET)##############\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# 1. Divisione Train / Validation (80% / 20%) sul dataset di training\n",
        "total_size = len(train_val_dataset)\n",
        "train_len = int(0.8 * total_size)\n",
        "val_len = total_size - train_len\n",
        "\n",
        "generator = torch.Generator().manual_seed(SEED_VALUE)\n",
        "\n",
        "# Passiamo il generator a random_split\n",
        "train_subset, val_subset = random_split(\n",
        "    train_val_dataset,\n",
        "    [train_len, val_len],\n",
        "    generator=generator  # <--- QUESTO GARANTISCE CHE LO SPLIT SIA SEMPRE IDENTICO\n",
        ")\n",
        "\n",
        "print(f\"üìä Split completato (dal set di Training/Validation):\")\n",
        "print(f\"   -> Training Set: {len(train_subset)} immagini\")\n",
        "print(f\"   -> Validation Set: {len(val_subset)} immagini\")\n",
        "print(f\"   -> Test Set (dal file test.csv): {len(test_dataset)} immagini\")\n",
        "\n",
        "# 2. Creazione dei DataLoader\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "# NOTA: Per il Validation, i dati vengono processati con i 'train' transforms (inclusa augmentation) perch√© lo split √® stato fatto prima.\n",
        "# Se volessimo la trasformazione 'val' per il validation, dovremmo ricreare i subset con i transforms corretti.\n",
        "# Per semplicit√†, manteniamo questa configurazione che √® quella originale.\n",
        "\n",
        "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "# Il test_loader deve essere shuffle=False per una valutazione ordinata\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(f\"‚úÖ Dataloaders pronti (Batch size: {BATCH_SIZE})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjMKEnk_ldxd",
        "outputId": "5c6ba5cc-e5b2-4031-8140-23e20e4d7b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaricamento pesi ResNet50 (ImageNet)...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 135MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Modello ResNet50 caricato e modificato per 30 classi.\n",
            "   -> Backbone (corpo): Congelato ‚ùÑÔ∏è\n",
            "   -> Head (testa): Pronta per l'addestramento üî•\n"
          ]
        }
      ],
      "source": [
        "###############CELLA 5###################\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_model(num_classes=30):\n",
        "    print(\"Scaricamento pesi ResNet50 (ImageNet)...\")\n",
        "    # Scarichiamo la versione pi√π aggiornata dei pesi\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "    # 1. FREEZING: Congeliamo tutti i parametri\n",
        "    # Questo impedisce che durante il training modifichiamo i filtri che sanno gi√† \"vedere\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 2. Sostituzione dell'ultimo layer (Fully Connected)\n",
        "    # ResNet50 ha 2048 feature in ingresso all'ultimo layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "\n",
        "    # Creiamo il nuovo layer classificatore.\n",
        "    # Nota: Di default, i nuovi layer hanno requires_grad=True, quindi QUESTI verranno addestrati.\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512), # Strato intermedio per imparare combinazioni complesse\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),          # Dropout per evitare overfitting (tecnica standard)\n",
        "        nn.Linear(512, num_classes) # Output finale: 30 probabilit√†\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Istanziamo il modello e lo spostiamo sulla GPU\n",
        "model = get_model(num_classes=len(train_val_dataset.classes))\n",
        "model = model.to(device) # Sposta tutto sulla GPU T4\n",
        "\n",
        "print(\"\\nü§ñ Modello ResNet50 caricato e modificato per 30 classi.\")\n",
        "print(\"   -> Backbone (corpo): Congelato ‚ùÑÔ∏è\")\n",
        "print(\"   -> Head (testa): Pronta per l'addestramento üî•\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVFl2zD0kibA",
        "outputId": "3f0525cd-b0d9-4855-f6e6-266e62c6cfdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Il modello migliore verr√† salvato in: /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth\n",
            "\n",
            "üî• FASE 1: WARM-UP (Addestramento veloce solo della testa)...\n",
            "\n",
            "Epoch 1/4 [Fase 1 (Warm-Up)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-03 | \n",
            "train Loss: 2.9221 Acc: 0.1927\n",
            "val Loss: 2.7351 Acc: 0.2370\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 2/4 [Fase 1 (Warm-Up)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-03 | \n",
            "train Loss: 2.7363 Acc: 0.2378\n",
            "val Loss: 2.6928 Acc: 0.2554\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 3/4 [Fase 1 (Warm-Up)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-03 | \n",
            "train Loss: 2.6664 Acc: 0.2540\n",
            "val Loss: 2.6734 Acc: 0.2547\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 4/4 [Fase 1 (Warm-Up)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-03 | \n",
            "train Loss: 2.6209 Acc: 0.2621\n",
            "val Loss: 2.6568 Acc: 0.2634\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Fase 1 (Warm-Up) completata in 19m 39s\n",
            "Miglior Val Loss di fase: 2.6568\n",
            "\n",
            "üîì FASE 2: FINE-TUNING (Raffinamento Layer4 e Testa)...\n",
            "Parametri da addestrare: 16,029,214\n",
            "   -> Carico pesi migliori precedenti per confronto...\n",
            "\n",
            "Epoch 1/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.4924 Acc: 0.2986\n",
            "val Loss: 2.6055 Acc: 0.2739\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 2/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.4353 Acc: 0.3062\n",
            "val Loss: 2.5844 Acc: 0.2820\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 3/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.3989 Acc: 0.3196\n",
            "val Loss: 2.5715 Acc: 0.2865\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 4/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.3614 Acc: 0.3278\n",
            "val Loss: 2.5597 Acc: 0.2907\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 5/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.3218 Acc: 0.3367\n",
            "val Loss: 2.5502 Acc: 0.2932\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 6/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.2891 Acc: 0.3444\n",
            "val Loss: 2.5442 Acc: 0.2918\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 7/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.2562 Acc: 0.3537\n",
            "val Loss: 2.5467 Acc: 0.2944\n",
            "‚ö†Ô∏è Patience: 1/6\n",
            "\n",
            "Epoch 8/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.2250 Acc: 0.3606\n",
            "val Loss: 2.5372 Acc: 0.2904\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 9/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.1928 Acc: 0.3683\n",
            "val Loss: 2.5372 Acc: 0.2966\n",
            "‚ö†Ô∏è Patience: 1/6\n",
            "\n",
            "Epoch 10/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.1651 Acc: 0.3730\n",
            "val Loss: 2.5464 Acc: 0.2989\n",
            "‚ö†Ô∏è Patience: 2/6\n",
            "\n",
            "Epoch 11/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.1323 Acc: 0.3825\n",
            "val Loss: 2.5284 Acc: 0.2937\n",
            "‚úÖ Miglioramento! Salvataggio in /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth...\n",
            "\n",
            "Epoch 12/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.0952 Acc: 0.3914\n",
            "val Loss: 2.5463 Acc: 0.3037\n",
            "‚ö†Ô∏è Patience: 1/6\n",
            "\n",
            "Epoch 13/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.0657 Acc: 0.4004\n",
            "val Loss: 2.5469 Acc: 0.2962\n",
            "‚ö†Ô∏è Patience: 2/6\n",
            "\n",
            "Epoch 14/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 2.0297 Acc: 0.4068\n",
            "val Loss: 2.5548 Acc: 0.2961\n",
            "‚ö†Ô∏è Patience: 3/6\n",
            "\n",
            "Epoch 15/30 [Fase 2 (Fine-Tuning)]\n",
            "----------\n",
            "üìâ LR Group 0: 1.0e-05 | üìâ LR Group 1: 1.0e-04 | \n",
            "train Loss: 1.9961 Acc: 0.4183\n"
          ]
        }
      ],
      "source": [
        "################## CELLA 6 (AGGIORNATA CON WARM-UP) #################\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from torchvision import models\n",
        "import os\n",
        "\n",
        "# --- 0. CONFIGURAZIONE SALVATAGGIO ---\n",
        "SAVE_PATH = '/content/drive/MyDrive/Modelli_BookCover'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "MODEL_NAME = 'best_resnet50_finetuned.pth'\n",
        "FULL_MODEL_PATH = os.path.join(SAVE_PATH, MODEL_NAME)\n",
        "\n",
        "print(f\"üíæ Il modello migliore verr√† salvato in: {FULL_MODEL_PATH}\")\n",
        "\n",
        "# Loss Function (uguale per tutti)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- DEFINIZIONE FUNZIONE DI TRAINING (Invariata nella logica) ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, es_patience=6, phase_name=\"Training\"):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Se esiste gi√† un file pesi (es. dalla fase warm-up), carichiamo il best attuale come punto di partenza per il confronto\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Se stiamo facendo la Fase 2, proviamo a leggere la best loss precedente per non sovrascrivere con modelli peggiori\n",
        "    if os.path.exists(FULL_MODEL_PATH) and phase_name == \"Fase 2 (Fine-Tuning)\":\n",
        "        print(\"   -> Carico pesi migliori precedenti per confronto...\")\n",
        "        # Nota: qui servirebbe salvare anche la loss, per semplicit√† resettiamo il confronto ma partiamo dai pesi buoni\n",
        "        # La logica standard resetta il best_val_loss qui per permettere il saving nella nuova fase\n",
        "\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs} [{phase_name}]')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Stampa LR correnti\n",
        "        for i, param_group in enumerate(optimizer.param_groups):\n",
        "            print(f\"üìâ LR Group {i}: {param_group['lr']:.1e}\", end=\" | \")\n",
        "        print()\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total_samples = 0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                total_samples += inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / total_samples\n",
        "            epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "            if phase == 'val':\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # --- LOGICA SALVATAGGIO ---\n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_val_loss:\n",
        "                    best_val_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    patience_counter = 0\n",
        "                    print(f\"‚úÖ Miglioramento! Salvataggio in {FULL_MODEL_PATH}...\")\n",
        "                    torch.save(model.state_dict(), FULL_MODEL_PATH)\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    print(f\"‚ö†Ô∏è Patience: {patience_counter}/{es_patience}\")\n",
        "\n",
        "        if patience_counter >= es_patience:\n",
        "            print(f\"\\n‚èπÔ∏è Early Stopping attivato durante {phase_name}!\")\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f'\\n{phase_name} completata in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Miglior Val Loss di fase: {best_val_loss:.4f}')\n",
        "\n",
        "    # Ricarichiamo i pesi migliori\n",
        "    model.load_state_dict(torch.load(FULL_MODEL_PATH))\n",
        "    return model\n",
        "\n",
        "# ==========================================\n",
        "# üöÄ FASE 1: WARM-UP (SOLO TESTA)\n",
        "# ==========================================\n",
        "print(\"\\nüî• FASE 1: WARM-UP (Addestramento veloce solo della testa)...\")\n",
        "\n",
        "# 1. Congeliamo TUTTO\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 2. Sblocchiamo SOLO la testa\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. Optimizer \"Aggressivo\" per la testa (LR pi√π alto)\n",
        "optimizer_warmup = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "scheduler_warmup = optim.lr_scheduler.ReduceLROnPlateau(optimizer_warmup, mode='min', factor=0.1, patience=2)\n",
        "\n",
        "# 4. Train Breve (es. 4 epoche)\n",
        "model = train_model(\n",
        "    model, train_loader, val_loader, criterion,\n",
        "    optimizer_warmup, scheduler_warmup,\n",
        "    num_epochs=4, es_patience=2, phase_name=\"Fase 1 (Warm-Up)\"\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# ‚ùÑÔ∏è FASE 2: FINE-TUNING (LAYER4 + TESTA)\n",
        "# ==========================================\n",
        "print(\"\\nüîì FASE 2: FINE-TUNING (Raffinamento Layer4 e Testa)...\")\n",
        "\n",
        "# 1. Sblocchiamo Layer 4 (oltre alla testa che √® gi√† sbloccata)\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verifica parametri sbloccati\n",
        "params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
        "print(f\"Parametri da addestrare: {sum(p.numel() for p in params_to_update):,}\")\n",
        "\n",
        "# 2. Optimizer \"Delicato\" (LR differenziati e bassi)\n",
        "optimizer_ft = optim.Adam([\n",
        "    {'params': model.layer4.parameters(), 'lr': 1e-5}, # Backbone: impara piano per non rovinare pesi ImageNet\n",
        "    {'params': model.fc.parameters(), 'lr': 1e-4}      # Testa: impara normalmente\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "scheduler_ft = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "# 3. Train Lungo\n",
        "model = train_model(\n",
        "    model, train_loader, val_loader, criterion,\n",
        "    optimizer_ft, scheduler_ft,\n",
        "    num_epochs=30, es_patience=6, phase_name=\"Fase 2 (Fine-Tuning)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMJNadJZkeyb",
        "outputId": "83958070-4fa9-4a53-b2bd-712a79df2806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Trovato modello salvato: /content/drive/MyDrive/Modelli_BookCover/best_resnet50_finetuned.pth\n",
            "‚úÖ Pesi caricati con successo! Il modello √® pronto per la valutazione.\n",
            "‚è≠Ô∏è Ora puoi eseguire direttamente le celle 7 e 8.\n"
          ]
        }
      ],
      "source": [
        "################## CELLA DI CARICAMENTO (NO TRAINING) #################\n",
        "'''#######NEL CASO IN CUI TU VOGLIA CARICARE UN MODELLO SALVATO IN PRECEDENZA NEL DRIVE\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# 1. Definizione Percorso (Lo stesso usato per il salvataggio)\n",
        "SAVE_PATH = '/content/drive/MyDrive/Modelli_BookCover'\n",
        "MODEL_NAME = 'best_resnet50_finetuned.pth'\n",
        "FULL_MODEL_PATH = os.path.join(SAVE_PATH, MODEL_NAME)\n",
        "\n",
        "# 2. Verifica esistenza file\n",
        "if os.path.exists(FULL_MODEL_PATH):\n",
        "    print(f\"üìÇ Trovato modello salvato: {FULL_MODEL_PATH}\")\n",
        "\n",
        "    # 3. Caricamento dei pesi nello scheletro creato nella Cella 5\n",
        "    # map_location assicura che funzioni sia su CPU che GPU\n",
        "    state_dict = torch.load(FULL_MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    # Spostiamo il modello sulla GPU (se disponibile)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Mettiamo il modello in modalit√† valutazione (blocca dropout, batchnorm, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"‚úÖ Pesi caricati con successo! Il modello √® pronto per la valutazione.\")\n",
        "    print(\"‚è≠Ô∏è Ora puoi eseguire direttamente le celle 7 e 8.\")\n",
        "else:\n",
        "    print(f\"‚ùå ERRORE: Non trovo il file in {FULL_MODEL_PATH}\")\n",
        "    print(\"Assicurati di aver fatto almeno un training completo in precedenza.\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Mou0UYgdKN"
      },
      "outputs": [],
      "source": [
        "##################CELLA 7#################\n",
        "'''import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(model, dataloader, classes):\n",
        "    model.eval() # Modalit√† valutazione\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    print(\"üìä Calcolo delle predizioni sul Validation Set...\")\n",
        "    with torch.no_grad(): # Disabilita il calcolo dei gradienti (risparmia memoria)\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Spostiamo su CPU e convertiamo in numpy\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calcolo della matrice\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Normalizzazione (opzionale, per vedere le % invece dei numeri assoluti)\n",
        "    # cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(20, 16)) # Dimensioni grandi per farci stare 30 classi\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "\n",
        "    plt.ylabel('Vero Genere (True Label)', fontsize=14)\n",
        "    plt.xlabel('Genere Predetto (Predicted Label)', fontsize=14)\n",
        "    plt.title('Matrice di Confusione - Generi Letterari', fontsize=18)\n",
        "    plt.xticks(rotation=90) # Ruota le etichette per leggerle meglio\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "# Eseguiamo la funzione usando il modello addestrato\n",
        "# Assicurati che 'trained_model' sia disponibile (dopo la Cella 6)\n",
        "print(\"Generazione grafico in corso...\")\n",
        "plot_confusion_matrix(model, test_loader, train_val_dataset.classes)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Hsj7PXwZ2Af-",
        "outputId": "68170c36-1bbe-4ccf-8441-92b946e84b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìè Calcolo metriche Top-k (Come nel Paper)...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2587737758.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Esegui la valutazione\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mevaluate_paper_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2587737758.py\u001b[0m in \u001b[0;36mevaluate_paper_metrics\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# 1. Calcoliamo l'output del modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# 2. Prendiamo le prime 3 predizioni pi√π alte (Top-3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "################## CELLA 8#################\n",
        "#METRICHE PAPER (TOP-1, TOP-2, TOP-3)\n",
        "def evaluate_paper_metrics(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    correct_top1 = 0\n",
        "    correct_top2 = 0\n",
        "    correct_top3 = 0\n",
        "    total = 0\n",
        "\n",
        "    print(\"üìè Calcolo metriche Top-k (Come nel Paper)...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 1. Calcoliamo l'output del modello\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 2. Prendiamo le prime 3 predizioni pi√π alte (Top-3)\n",
        "            # k=3 perch√© ci servono Top-1, Top-2 e Top-3\n",
        "            _, max_k_preds = torch.topk(outputs, k=3, dim=1)\n",
        "\n",
        "            # 3. Trasponiamo la matrice per facilitare il confronto\n",
        "            # Ora max_k_preds ha shape [3, batch_size]\n",
        "            max_k_preds = max_k_preds.t()\n",
        "\n",
        "            # 4. Creiamo una matrice di etichette ripetute per confrontarle\n",
        "            target_expanded = labels.view(1, -1).expand_as(max_k_preds)\n",
        "\n",
        "            # 5. Confronto: Otteniamo una matrice di True/False\n",
        "            # Se la cella (k, i) √® True, vuol dire che la k-esima predizione per l'immagine i √® corretta\n",
        "            correct = max_k_preds.eq(target_expanded)\n",
        "\n",
        "            # --- AGGIORNAMENTO CONTATORI ---\n",
        "\n",
        "            # Top-1: Controlliamo solo la prima riga (la predizione #1)\n",
        "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            # Top-2: Controlliamo le prime due righe (predizione #1 O predizione #2)\n",
        "            correct_top2 += correct[:2].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            # Top-3: Controlliamo le prime tre righe\n",
        "            correct_top3 += correct[:3].reshape(-1).float().sum(0, keepdim=True)\n",
        "\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # Calcolo percentuali finali\n",
        "    acc_top1 = correct_top1.item() / total * 100\n",
        "    acc_top2 = correct_top2.item() / total * 100\n",
        "    acc_top3 = correct_top3.item() / total * 100\n",
        "\n",
        "    print(f\"\\nüìä RISULTATI DEL PAPER (su {total} immagini di test):\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"üîπ Top-1 Accuracy: {acc_top1:.2f}%  (Paper AlexNet: 24.7%)\")\n",
        "    print(f\"üîπ Top-2 Accuracy: {acc_top2:.2f}%  (Paper AlexNet: 33.1%)\")\n",
        "    print(f\"üîπ Top-3 Accuracy: {acc_top3:.2f}%  (Paper AlexNet: 40.3%)\")\n",
        "    print(\"-\" * 40)\n",
        "    return acc_top1, acc_top2, acc_top3\n",
        "\n",
        "# Esegui la valutazione\n",
        "evaluate_paper_metrics(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
